#!/usr/bin/env node

/**
 * Skrypt do analizy struktury historycznej bazy danych deximstr_hydro.sql
 * Sprawdza kompatybilnoÅ›Ä‡ z aktualnÄ… strukturÄ… Supabase
 */

const fs = require('fs');
const path = require('path');

console.log('ğŸ” Analiza struktury historycznej bazy danych...\n');

// Funkcja do analizy pliku SQL
function analyzeSQLFile(filePath) {
    if (!fs.existsSync(filePath)) {
        console.log('âŒ Plik nie zostaÅ‚ znaleziony:', filePath);
        console.log('ğŸ“ Instrukcje:');
        console.log('1. UmieÅ›Ä‡ plik deximstr_hydro.sql w katalogu gÅ‚Ã³wnym projektu');
        console.log('2. Uruchom ponownie: node scripts/analyze-historical-db.js');
        return;
    }

    const fileSize = fs.statSync(filePath).size;
    console.log(`ğŸ“Š Rozmiar pliku: ${(fileSize / 1024 / 1024).toFixed(2)} MB`);

    // Czytamy pierwsze 50KB pliku do analizy struktury
    const buffer = Buffer.alloc(50 * 1024);
    const fd = fs.openSync(filePath, 'r');
    const bytesRead = fs.readSync(fd, buffer, 0, buffer.length, 0);
    fs.closeSync(fd);

    const content = buffer.toString('utf8', 0, bytesRead);
    
    console.log('\nğŸ—ï¸  ANALIZA STRUKTURY:');
    console.log('=' * 50);

    // Szukamy definicji tabel
    const tableMatches = content.match(/CREATE TABLE[^;]+;/gi) || [];
    console.log(`\nğŸ“‹ Znalezione tabele: ${tableMatches.length}`);
    
    tableMatches.forEach((table, index) => {
        const tableName = table.match(/CREATE TABLE\s+`?(\w+)`?/i)?.[1];
        console.log(`${index + 1}. ${tableName}`);
        
        // Analizujemy kolumny
        const columns = table.match(/`(\w+)`\s+([^,\n]+)/g) || [];
        columns.forEach(col => {
            const [, name, type] = col.match(/`(\w+)`\s+([^,\n]+)/) || [];
            if (name && type) {
                console.log(`   - ${name}: ${type.trim()}`);
            }
        });
        console.log('');
    });

    // Szukamy INSERT statements
    const insertMatches = content.match(/INSERT INTO[^;]+;/gi) || [];
    console.log(`ğŸ“¥ Znalezione INSERT statements: ${insertMatches.length}`);

    // Sprawdzamy czy sÄ… dane pomiarÃ³w
    const measurementKeywords = ['measurement', 'water_level', 'flow', 'timestamp', 'date'];
    const hasMeasurements = measurementKeywords.some(keyword => 
        content.toLowerCase().includes(keyword)
    );
    
    console.log(`\nğŸŒŠ Zawiera pomiary historyczne: ${hasMeasurements ? 'âœ… TAK' : 'âŒ NIE'}`);

    // Analiza kompatybilnoÅ›ci
    console.log('\nğŸ”„ KOMPATYBILNOÅšÄ† Z SUPABASE:');
    console.log('=' * 50);
    
    const supabaseStructure = {
        stations: ['id', 'station_code', 'station_name', 'river_name', 'voivodeship', 'latitude', 'longitude', 'warning_level', 'alarm_level'],
        measurements: ['id', 'station_id', 'measurement_timestamp', 'water_level', 'flow_rate', 'temperature', 'source'],
        alerts: ['id', 'station_id', 'alert_type', 'message', 'water_level', 'threshold_level']
    };

    Object.entries(supabaseStructure).forEach(([tableName, expectedColumns]) => {
        const tableExists = content.toLowerCase().includes(`create table \`${tableName}\``);
        console.log(`\nğŸ“‹ Tabela '${tableName}': ${tableExists ? 'âœ… ISTNIEJE' : 'âŒ BRAK'}`);
        
        if (tableExists) {
            expectedColumns.forEach(column => {
                const columnExists = content.toLowerCase().includes(`\`${column}\``);
                console.log(`   - ${column}: ${columnExists ? 'âœ…' : 'âŒ'}`);
            });
        }
    });

    return {
        fileSize,
        tableCount: tableMatches.length,
        insertCount: insertMatches.length,
        hasMeasurements,
        tables: tableMatches.map(t => t.match(/CREATE TABLE\s+`?(\w+)`?/i)?.[1]).filter(Boolean)
    };
}

// Funkcja do generowania planu migracji
function generateMigrationPlan(analysis) {
    console.log('\nğŸ“‹ PLAN MIGRACJI:');
    console.log('=' * 50);
    
    console.log('\n1. ğŸ” ANALIZA SZCZEGÃ“ÅOWA:');
    console.log('   - SprawdÅº peÅ‚nÄ… strukturÄ™ tabel w pliku SQL');
    console.log('   - Zidentyfikuj mapowanie kolumn MySQL â†’ PostgreSQL');
    console.log('   - SprawdÅº typy danych i ograniczenia');
    
    console.log('\n2. ğŸ› ï¸  PRZYGOTOWANIE:');
    console.log('   - UtwÃ³rz skrypt konwersji MySQL â†’ PostgreSQL');
    console.log('   - Przygotuj mapowanie ID stacji');
    console.log('   - Zaplanuj import w partiach (chunking)');
    
    console.log('\n3. ğŸ“¥ IMPORT:');
    console.log('   - Import stacji (jeÅ›li nowe)');
    console.log('   - Import pomiarÃ³w historycznych');
    console.log('   - Weryfikacja integralnoÅ›ci danych');
    
    console.log('\n4. âœ… WERYFIKACJA:');
    console.log('   - SprawdÅº liczbÄ™ zaimportowanych rekordÃ³w');
    console.log('   - Przetestuj API z historycznymi danymi');
    console.log('   - SprawdÅº wydajnoÅ›Ä‡ zapytaÅ„');
}

// GÅ‚Ã³wna funkcja
function main() {
    const sqlFile = path.join(process.cwd(), 'deximstr_hydro.sql');
    
    console.log('ğŸŒŠ HYDRO API - Analiza Historycznej Bazy Danych');
    console.log('=' * 60);
    console.log(`ğŸ“ Szukam pliku: ${sqlFile}\n`);
    
    const analysis = analyzeSQLFile(sqlFile);
    
    if (analysis) {
        generateMigrationPlan(analysis);
        
        console.log('\nğŸ¯ NASTÄ˜PNE KROKI:');
        console.log('=' * 50);
        console.log('1. UmieÅ›Ä‡ plik deximstr_hydro.sql w katalogu gÅ‚Ã³wnym');
        console.log('2. Uruchom: node scripts/analyze-historical-db.js');
        console.log('3. Przejrzyj szczegÃ³Å‚owÄ… analizÄ™ struktury');
        console.log('4. Uruchom import: node scripts/import-historical-data.js');
    }
}

if (require.main === module) {
    main();
}

module.exports = { analyzeSQLFile, generateMigrationPlan }; 