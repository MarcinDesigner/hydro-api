# ğŸŒŠ Przewodnik po Danych Historycznych - Hydro API

## ğŸ“‹ PrzeglÄ…d

Ten przewodnik opisuje jak zaimportowaÄ‡ i wykorzystaÄ‡ historyczne dane pomiarÃ³w hydrologicznych w systemie Hydro API.

## ğŸ—ï¸ Struktura Danych

### KompatybilnoÅ›Ä‡ MySQL â†’ PostgreSQL

| MySQL | PostgreSQL | Opis |
|-------|------------|------|
| `int(11)` | `INTEGER` | Liczby caÅ‚kowite |
| `varchar(255)` | `TEXT` | Tekst |
| `decimal(10,6)` | `DOUBLE PRECISION` | WspÃ³Å‚rzÄ™dne GPS |
| `tinyint(1)` | `BOOLEAN` | WartoÅ›ci logiczne |
| `timestamp` | `TIMESTAMP WITH TIME ZONE` | Daty z strefÄ… czasowÄ… |

### Mapowanie Tabel

#### Tabela `stations`
```sql
-- MySQL
CREATE TABLE `stations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `station_code` varchar(15) NOT NULL,
  `station_name` varchar(100) NOT NULL,
  `river_name` varchar(100) DEFAULT NULL,
  `voivodeship` varchar(50) DEFAULT NULL,
  `longitude` decimal(10,6) NOT NULL,
  `latitude` decimal(10,6) NOT NULL,
  `warning_level` int(11) DEFAULT NULL,
  `alarm_level` int(11) DEFAULT NULL,
  `api_visible` tinyint(1) DEFAULT 1,
  `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- PostgreSQL (Supabase)
CREATE TABLE stations (
    id TEXT PRIMARY KEY DEFAULT gen_random_uuid()::text,
    station_code TEXT UNIQUE NOT NULL,
    station_name TEXT NOT NULL,
    river_name TEXT,
    voivodeship TEXT,
    latitude DOUBLE PRECISION,
    longitude DOUBLE PRECISION,
    warning_level INTEGER,
    alarm_level INTEGER,
    api_visible BOOLEAN DEFAULT true NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL
);
```

#### Tabela `measurements` (historyczne pomiary)
```sql
-- Oczekiwana struktura MySQL
CREATE TABLE `measurements` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `station_id` int(11) NOT NULL,
  `measurement_timestamp` timestamp NOT NULL,
  `water_level` int(11) DEFAULT NULL,
  `flow_rate` decimal(10,3) DEFAULT NULL,
  `temperature` decimal(5,2) DEFAULT NULL,
  `source` varchar(50) DEFAULT 'historical',
  `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- PostgreSQL (Supabase)
CREATE TABLE measurements (
    id TEXT PRIMARY KEY DEFAULT gen_random_uuid()::text,
    station_id TEXT NOT NULL REFERENCES stations(id) ON DELETE CASCADE,
    measurement_timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    water_level INTEGER,
    flow_rate DOUBLE PRECISION,
    temperature DOUBLE PRECISION,
    source TEXT NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now() NOT NULL
);
```

## ğŸ› ï¸ Proces Importu

### Krok 1: Analiza Struktury

```bash
# UmieÅ›Ä‡ plik deximstr_hydro.sql w katalogu gÅ‚Ã³wnym
cp /path/to/deximstr_hydro.sql ./

# Uruchom analizÄ™ struktury
node scripts/analyze-historical-db.js
```

**Oczekiwany wynik:**
```
ğŸŒŠ HYDRO API - Analiza Historycznej Bazy Danych
============================================================
ğŸ“ Szukam pliku: /path/to/hydro-api/deximstr_hydro.sql

ğŸ“Š Rozmiar pliku: 52.34 MB

ğŸ—ï¸  ANALIZA STRUKTURY:
==================================================

ğŸ“‹ Znalezione tabele: 2
1. stations
   - id: int(11) NOT NULL AUTO_INCREMENT
   - station_code: varchar(15) NOT NULL
   - station_name: varchar(100) NOT NULL
   - river_name: varchar(100) DEFAULT NULL
   - voivodeship: varchar(50) DEFAULT NULL
   - longitude: decimal(10,6) NOT NULL
   - latitude: decimal(10,6) NOT NULL
   - warning_level: int(11) DEFAULT NULL
   - alarm_level: int(11) DEFAULT NULL

2. measurements
   - id: int(11) NOT NULL AUTO_INCREMENT
   - station_id: int(11) NOT NULL
   - measurement_timestamp: timestamp NOT NULL
   - water_level: int(11) DEFAULT NULL
   - flow_rate: decimal(10,3) DEFAULT NULL
   - temperature: decimal(5,2) DEFAULT NULL

ğŸ“¥ Znalezione INSERT statements: 1247

ğŸŒŠ Zawiera pomiary historyczne: âœ… TAK

ğŸ”„ KOMPATYBILNOÅšÄ† Z SUPABASE:
==================================================

ğŸ“‹ Tabela 'stations': âœ… ISTNIEJE
   - id: âœ…
   - station_code: âœ…
   - station_name: âœ…
   - river_name: âœ…
   - voivodeship: âœ…
   - latitude: âœ…
   - longitude: âœ…
   - warning_level: âœ…
   - alarm_level: âœ…

ğŸ“‹ Tabela 'measurements': âœ… ISTNIEJE
   - id: âœ…
   - station_id: âœ…
   - measurement_timestamp: âœ…
   - water_level: âœ…
   - flow_rate: âœ…
   - temperature: âœ…
   - source: âŒ
```

### Krok 2: Import Testowy (Dry Run)

```bash
# Uruchom import w trybie testowym
node scripts/import-historical-data.js --dry-run

# Lub z mniejszymi partiami
node scripts/import-historical-data.js --dry-run --batch-size 500
```

### Krok 3: Import Produkcyjny

```bash
# Import rzeczywisty
node scripts/import-historical-data.js

# Z konfiguracjÄ…
node scripts/import-historical-data.js --batch-size 1000
```

**Oczekiwany wynik:**
```
ğŸŒŠ HYDRO API - Import Historycznych Danych
============================================================
ğŸ“ Plik SQL: /path/to/hydro-api/deximstr_hydro.sql
âš™ï¸  Konfiguracja: batch=1000, dryRun=false

ğŸ“– Czytanie pliku SQL...
ğŸ“Š Rozmiar pliku: 52.34 MB
ğŸ“‹ Znaleziono tabelÄ™: stations (12 kolumn)
ğŸ“‹ Znaleziono tabelÄ™: measurements (7 kolumn)
ğŸ“¥ Tabela stations: 872 rekordÃ³w
ğŸ“¥ Tabela measurements: 125847 rekordÃ³w

ğŸ”Œ Sprawdzanie poÅ‚Ä…czenia z bazÄ…...
âœ… PoÅ‚Ä…czono z Supabase

ğŸ“¥ Import tabeli stations: 872 rekordÃ³w
âœ… Partia 1: 872 rekordÃ³w
ğŸ“Š Stacje - Sukces: 872, BÅ‚Ä™dy: 0

ğŸ“¥ Import tabeli measurements: 125847 rekordÃ³w
âœ… Partia 1: 1000 rekordÃ³w
âœ… Partia 2: 1000 rekordÃ³w
...
âœ… Partia 126: 847 rekordÃ³w
ğŸ“Š Pomiary - Sukces: 125847, BÅ‚Ä™dy: 0

ğŸ‰ Import zakoÅ„czony!
```

## ğŸ“Š API Endpoints dla Danych Historycznych

### GET `/api/stations/[id]/history`

Pobiera historyczne pomiary dla konkretnej stacji.

#### Parametry zapytania:
- `start_date` - Data poczÄ…tkowa (ISO 8601)
- `end_date` - Data koÅ„cowa (ISO 8601)
- `limit` - Liczba rekordÃ³w (max 1000, domyÅ›lnie 100)
- `offset` - PrzesuniÄ™cie dla paginacji
- `order_by` - Sortowanie: `asc` lub `desc` (domyÅ›lnie `desc`)

#### PrzykÅ‚ady uÅ¼ycia:

```bash
# Ostatnie 100 pomiarÃ³w
curl "https://hydro-api.vercel.app/api/stations/150170080/history"

# Pomiary z ostatniego miesiÄ…ca
curl "https://hydro-api.vercel.app/api/stations/150170080/history?start_date=2024-05-01&end_date=2024-05-31"

# Paginacja
curl "https://hydro-api.vercel.app/api/stations/150170080/history?limit=50&offset=100"

# Chronologicznie (najstarsze pierwsze)
curl "https://hydro-api.vercel.app/api/stations/150170080/history?order_by=asc"
```

#### PrzykÅ‚ad odpowiedzi:

```json
{
  "station": {
    "id": "station_150170080",
    "stationCode": "150170080",
    "stationName": "JARNOÅTÃ“WEK",
    "riverName": "ZÅ‚oty Potok",
    "voivodeship": "opolskie"
  },
  "measurements": [
    {
      "id": "measurement_12345",
      "measurementTimestamp": "2024-05-15T12:00:00Z",
      "waterLevel": 125,
      "flowRate": 2.45,
      "temperature": 18.5,
      "source": "historical",
      "createdAt": "2024-05-15T12:05:00Z"
    }
  ],
  "pagination": {
    "limit": 100,
    "offset": 0,
    "total": 2847,
    "hasMore": true
  },
  "statistics": {
    "totalMeasurements": 2847,
    "averageWaterLevel": 118.7,
    "averageFlowRate": 2.12,
    "averageTemperature": 16.8,
    "minWaterLevel": 85,
    "maxWaterLevel": 245,
    "dataRange": {
      "oldest": "2023-01-01T00:00:00Z",
      "newest": "2024-05-15T12:00:00Z"
    }
  },
  "monthlyStats": [
    {
      "month": "2024-05-01T00:00:00Z",
      "count": 744,
      "avgWaterLevel": 122.5,
      "minWaterLevel": 95,
      "maxWaterLevel": 165,
      "avgFlowRate": 2.34
    }
  ],
  "filters": {
    "startDate": null,
    "endDate": null,
    "orderBy": "desc"
  },
  "timestamp": "2024-05-15T14:30:00Z"
}
```

## ğŸ” Weryfikacja Importu

### Sprawdzenie liczby rekordÃ³w

```bash
# SprawdÅº liczbÄ™ stacji
curl "https://hydro-api.vercel.app/api/stats" | jq '.totalStations'

# SprawdÅº liczbÄ™ pomiarÃ³w
curl "https://hydro-api.vercel.app/api/database-stats" | jq '.totalMeasurements'
```

### Test konkretnej stacji

```bash
# SprawdÅº czy stacja ma dane historyczne
curl "https://hydro-api.vercel.app/api/stations/150170080/history?limit=1"
```

## ğŸš€ KorzyÅ›ci z Danych Historycznych

### 1. **Analiza TrendÃ³w**
- DÅ‚ugoterminowe zmiany poziomÃ³w wody
- SezonowoÅ›Ä‡ i cykle hydrologiczne
- Identyfikacja anomalii

### 2. **Prognozowanie**
- Modele predykcyjne oparte na danych historycznych
- Wczesne ostrzeganie o powodziach
- Planowanie gospodarki wodnej

### 3. **Statystyki Zaawansowane**
- Percentyle i kwantyle
- Analiza czÄ™stotliwoÅ›ci zdarzeÅ„ ekstremalnych
- Korelacje miÄ™dzy stacjami

### 4. **Wizualizacje**
- Wykresy czasowe
- Mapy cieplne sezonowoÅ›ci
- PorÃ³wnania miÄ™dzyroczne

## âš ï¸ Uwagi Techniczne

### WydajnoÅ›Ä‡
- Indeksy na `station_id` i `measurement_timestamp`
- Paginacja dla duÅ¼ych zbiorÃ³w danych
- Cache dla czÄ™sto uÅ¼ywanych zapytaÅ„

### BezpieczeÅ„stwo
- Rate limiting dla API
- Walidacja parametrÃ³w wejÅ›ciowych
- Sanityzacja danych SQL

### Monitoring
- Logi importu
- Metryki wydajnoÅ›ci
- Alerty o bÅ‚Ä™dach

## ğŸ¯ NastÄ™pne Kroki

1. **UmieÅ›Ä‡ plik `deximstr_hydro.sql` w katalogu gÅ‚Ã³wnym**
2. **Uruchom analizÄ™**: `node scripts/analyze-historical-db.js`
3. **Test import**: `node scripts/import-historical-data.js --dry-run`
4. **Import produkcyjny**: `node scripts/import-historical-data.js`
5. **Weryfikacja**: SprawdÅº API endpoints
6. **Integracja**: Dodaj do dashboardu i statystyk

---

**Ostatnia aktualizacja**: 2025-06-06  
**Wersja**: 1.0.0  
**Status**: Ready for Import 